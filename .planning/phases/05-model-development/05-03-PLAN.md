---
phase: 05-model-development
plan: 03
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - packages/backend/src/lineupiq/models/rb.py
  - packages/backend/tests/test_rb_models.py
  - packages/backend/models/RB_rushing_yards.joblib
  - packages/backend/models/RB_rushing_tds.joblib
  - packages/backend/models/RB_carries.joblib
  - packages/backend/models/RB_receiving_yards.joblib
  - packages/backend/models/RB_receptions.joblib
autonomous: true
---

<objective>
Train XGBoost models for RB stats (rushing_yards, rushing_tds, carries, receiving_yards, receptions) using Optuna hyperparameter tuning and TimeSeriesSplit validation.

Purpose: Create accurate RB stat prediction models covering both rushing and receiving stats.
Output: Trained and persisted RB models with documented performance metrics.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-model-development/05-RESEARCH.md
@.planning/phases/05-model-development/05-01-SUMMARY.md

@packages/backend/src/lineupiq/features/pipeline.py
@packages/backend/src/lineupiq/models/training.py
@packages/backend/src/lineupiq/models/persistence.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create RB model training module</name>
  <files>packages/backend/src/lineupiq/models/rb.py, packages/backend/src/lineupiq/models/__init__.py</files>
  <action>
Create rb.py with:
1. `RB_TARGETS = ["rushing_yards", "rushing_tds", "carries", "receiving_yards", "receptions"]` - All RB targets
2. `prepare_rb_data(df)`:
   - Filter df where position == "RB"
   - Drop rows with null values in features or targets
   - Return X (features), y (targets dict), with feature columns from get_feature_columns()
3. `train_rb_models(seasons, n_trials=50)`:
   - Load features via build_features(seasons)
   - Prepare data via prepare_rb_data
   - For each target in RB_TARGETS:
     - Run tune_hyperparameters(X, y[target], n_trials=n_trials)
     - Train final model with best params
     - Save model via save_model(model, "RB", target, metadata)
   - Return dict of {target: (model, metrics)}

Update __init__.py to export: train_rb_models, RB_TARGETS

IMPORTANT:
- RBs have 5 targets (more than QB) - training will take longer
- Use same seasons list as QB training for consistency
- Filter to RB position (includes FB due to 03-02 decision)
  </action>
  <verify>uv run python -c "from lineupiq.models import train_rb_models, RB_TARGETS; print(RB_TARGETS)"</verify>
  <done>RB training module importable with train_rb_models function</done>
</task>

<task type="auto">
  <name>Task 2: Train and persist RB models</name>
  <files>packages/backend/models/RB_rushing_yards.joblib, packages/backend/models/RB_rushing_tds.joblib, packages/backend/models/RB_carries.joblib, packages/backend/models/RB_receiving_yards.joblib, packages/backend/models/RB_receptions.joblib</files>
  <action>
Run RB model training script:

```python
from lineupiq.models import train_rb_models
from lineupiq.models.persistence import list_models

# Train on recent 6 seasons (match QB training)
results = train_rb_models(seasons=[2019, 2020, 2021, 2022, 2023, 2024], n_trials=50)

# Print results
for target, (model, metrics) in results.items():
    print(f"RB {target}:")
    print(f"  CV RMSE: {metrics['cv_rmse_mean']:.2f} +/- {metrics['cv_rmse_std']:.2f}")
    print(f"  Best params: {metrics['best_params']}")

# Verify models saved
rb_models = [m for m in list_models() if m[0] == "RB"]
print(f"Saved RB models: {rb_models}")
```

If seasons list causes errors, try [2021, 2022, 2023, 2024].

Training may take 10-20 minutes with 50 trials x 5 targets. Expected RMSE ranges:
- rushing_yards: ~30-50
- rushing_tds: ~0.4-0.7
- carries: ~5-8
- receiving_yards: ~15-25
- receptions: ~1-2
  </action>
  <verify>uv run python -c "from lineupiq.models import list_models; models = [m for m in list_models() if m[0] == 'RB']; assert len(models) == 5; print('RB models saved:', models)"</verify>
  <done>All 5 RB models saved to packages/backend/models/</done>
</task>

<task type="auto">
  <name>Task 3: Add RB model tests</name>
  <files>packages/backend/tests/test_rb_models.py</files>
  <action>
Create tests for RB models:
1. test_prepare_rb_data_filters_position - Verify only RB data returned
2. test_prepare_rb_data_returns_correct_features - Feature count matches get_feature_columns()
3. test_train_rb_models_creates_models - Integration test (use n_trials=5 for speed)
4. test_rb_model_predictions_reasonable - Load saved models, predict on sample, verify:
   - rushing_yards predictions in range [0, 300]
   - rushing_tds predictions in range [0, 5]
   - carries predictions in range [0, 40]
   - receiving_yards predictions in range [0, 150]
   - receptions predictions in range [0, 15]

Use pytest fixtures for sample data. Keep integration tests fast with small n_trials.
  </action>
  <verify>cd packages/backend && uv run pytest tests/test_rb_models.py -v</verify>
  <done>All RB model tests pass</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] RB training module created with train_rb_models
- [ ] All 5 RB models trained and saved to packages/backend/models/
- [ ] Model metrics logged (CV RMSE for each target)
- [ ] All RB model tests pass
- [ ] Models produce reasonable predictions within expected ranges
</verification>

<success_criteria>

- All tasks completed
- RB models for all 5 targets trained and persisted
- Cross-validation RMSE documented for each target
- Predictions in reasonable ranges for each stat
</success_criteria>

<output>
After completion, create `.planning/phases/05-model-development/05-03-SUMMARY.md`
</output>
