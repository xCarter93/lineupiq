---
phase: 05-model-development
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/backend/pyproject.toml
  - packages/backend/src/lineupiq/models/__init__.py
  - packages/backend/src/lineupiq/models/training.py
  - packages/backend/src/lineupiq/models/persistence.py
  - packages/backend/tests/test_model_training.py
autonomous: true
---

<objective>
Create ML training infrastructure with XGBoost, Optuna hyperparameter tuning, TimeSeriesSplit validation, and model persistence.

Purpose: Establish the core training utilities that all position-specific model training plans will use.
Output: Models module with training, tuning, and persistence capabilities.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-model-development/05-RESEARCH.md

@packages/backend/src/lineupiq/features/pipeline.py
@packages/backend/pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install ML dependencies</name>
  <files>packages/backend/pyproject.toml</files>
  <action>Add xgboost, optuna, shap, joblib, matplotlib to dependencies. Use uv to sync the environment. Versions: xgboost>=2.1.0, optuna>=3.6.0, shap>=0.45.0, joblib>=1.3.0, matplotlib>=3.8.0. Run `uv sync` in packages/backend to install.</action>
  <verify>uv run python -c "import xgboost, optuna, shap, joblib, matplotlib; print('OK')"</verify>
  <done>All ML libraries importable without errors</done>
</task>

<task type="auto">
  <name>Task 2: Create training module with Optuna+TimeSeriesSplit</name>
  <files>packages/backend/src/lineupiq/models/__init__.py, packages/backend/src/lineupiq/models/training.py</files>
  <action>
Create models/ module structure:

training.py should contain:
1. `create_study(direction="minimize")` - Create Optuna study for hyperparameter search
2. `get_xgb_params(trial)` - Return XGBoost params from Optuna trial:
   - max_depth: 3-9
   - learning_rate: 0.01-0.3 (log scale)
   - n_estimators: 100-500
   - min_child_weight: 1-20
   - subsample: 0.6-1.0
   - colsample_bytree: 0.6-1.0
   - reg_alpha: 1e-8 to 10.0 (log scale)
   - reg_lambda: 1e-8 to 10.0 (log scale)
3. `train_model(X, y, params, n_splits=5)` - Train XGBRegressor with TimeSeriesSplit CV:
   - Use TimeSeriesSplit(n_splits=n_splits)
   - Return trained model and CV scores
   - shuffle=False for temporal integrity
4. `tune_hyperparameters(X, y, n_trials=50, n_splits=5)` - Run Optuna study:
   - Create objective function using get_xgb_params + train_model
   - Minimize negative RMSE
   - Return best params and study

__init__.py should export: create_study, train_model, tune_hyperparameters

IMPORTANT: Use TimeSeriesSplit, NOT KFold - prevents data leakage. Use sklearn's cross_val_score with scoring="neg_root_mean_squared_error".
  </action>
  <verify>uv run python -c "from lineupiq.models import train_model, tune_hyperparameters; print('OK')"</verify>
  <done>Training module importable with core functions</done>
</task>

<task type="auto">
  <name>Task 3: Create persistence module for model save/load</name>
  <files>packages/backend/src/lineupiq/models/persistence.py, packages/backend/src/lineupiq/models/__init__.py</files>
  <action>
Create persistence.py with:
1. `MODELS_DIR` constant pointing to packages/backend/models/ directory
2. `save_model(model, position, target, metadata)`:
   - Create artifact dict with model, metadata, feature_names
   - Save to MODELS_DIR/{position}_{target}.joblib
   - metadata should include: trained_at, n_samples, best_params, cv_scores
3. `load_model(position, target)`:
   - Load artifact from MODELS_DIR/{position}_{target}.joblib
   - Return (model, metadata) tuple
4. `list_models()`:
   - Return list of (position, target) tuples for all saved models

Update __init__.py to export: save_model, load_model, list_models

Use joblib.dump/load for persistence. Create MODELS_DIR if it doesn't exist.
  </action>
  <verify>uv run python -c "from lineupiq.models import save_model, load_model, list_models; print('OK')"</verify>
  <done>Persistence module exports save_model, load_model, list_models</done>
</task>

<task type="auto">
  <name>Task 4: Add unit tests for training infrastructure</name>
  <files>packages/backend/tests/test_model_training.py</files>
  <action>
Create tests for training module:
1. test_get_xgb_params_returns_valid_dict - Verify params have expected keys
2. test_train_model_returns_model_and_scores - Test with small synthetic data
3. test_train_model_uses_timeseries_split - Verify temporal CV (no future leakage)
4. test_tune_hyperparameters_returns_best_params - Quick 5-trial test
5. test_save_and_load_model_roundtrip - Save model, load it, verify same predictions
6. test_list_models_finds_saved - Save a model, verify list_models includes it

Use small synthetic data (100-200 rows) for fast tests. Create fixture with random features and target.
  </action>
  <verify>cd packages/backend && uv run pytest tests/test_model_training.py -v</verify>
  <done>All 6 training infrastructure tests pass</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `uv sync` completes without errors in packages/backend
- [ ] All ML libraries importable (xgboost, optuna, shap, joblib, matplotlib)
- [ ] Training module exports train_model, tune_hyperparameters
- [ ] Persistence module exports save_model, load_model, list_models
- [ ] All 6 unit tests pass
- [ ] No TypeScript/Python errors
</verification>

<success_criteria>

- All tasks completed
- Training infrastructure ready for position-specific model training
- TimeSeriesSplit used (not KFold) for temporal integrity
- Model save/load works end-to-end
</success_criteria>

<output>
After completion, create `.planning/phases/05-model-development/05-01-SUMMARY.md`
</output>
