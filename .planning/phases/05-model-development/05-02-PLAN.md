---
phase: 05-model-development
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - packages/backend/src/lineupiq/models/qb.py
  - packages/backend/tests/test_qb_models.py
  - packages/backend/models/QB_passing_yards.joblib
  - packages/backend/models/QB_passing_tds.joblib
autonomous: true
---

<objective>
Train XGBoost models for QB passing stats (passing_yards, passing_tds) using Optuna hyperparameter tuning and TimeSeriesSplit validation.

Purpose: Create accurate QB stat prediction models as the first position-specific training.
Output: Trained and persisted QB models with documented performance metrics.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-model-development/05-RESEARCH.md
@.planning/phases/05-model-development/05-01-SUMMARY.md

@packages/backend/src/lineupiq/features/pipeline.py
@packages/backend/src/lineupiq/models/training.py
@packages/backend/src/lineupiq/models/persistence.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create QB model training module</name>
  <files>packages/backend/src/lineupiq/models/qb.py, packages/backend/src/lineupiq/models/__init__.py</files>
  <action>
Create qb.py with:
1. `QB_TARGETS = ["passing_yards", "passing_tds"]` - Target columns for QB
2. `prepare_qb_data(df)`:
   - Filter df where position == "QB"
   - Drop rows with null values in features or targets
   - Return X (features), y (targets dict), with feature columns from get_feature_columns()
3. `train_qb_models(seasons, n_trials=50)`:
   - Load features via build_features(seasons)
   - Prepare data via prepare_qb_data
   - For each target in QB_TARGETS:
     - Run tune_hyperparameters(X, y[target], n_trials=n_trials)
     - Train final model with best params
     - Save model via save_model(model, "QB", target, metadata)
   - Return dict of {target: (model, metrics)}

Update __init__.py to export: train_qb_models, QB_TARGETS

IMPORTANT:
- Use get_feature_columns() from features.pipeline for feature selection
- Filter to QB position BEFORE splitting features/targets
- Use 5+ recent seasons for sufficient data (e.g., [2019, 2020, 2021, 2022, 2023, 2024])
  </action>
  <verify>uv run python -c "from lineupiq.models import train_qb_models, QB_TARGETS; print(QB_TARGETS)"</verify>
  <done>QB training module importable with train_qb_models function</done>
</task>

<task type="auto">
  <name>Task 2: Train and persist QB models</name>
  <files>packages/backend/models/QB_passing_yards.joblib, packages/backend/models/QB_passing_tds.joblib</files>
  <action>
Run QB model training script:

```python
from lineupiq.models import train_qb_models
from lineupiq.models.persistence import list_models

# Train on recent 6 seasons (adjust based on data availability)
# Use n_trials=50 for decent tuning, increase to 100 for production
results = train_qb_models(seasons=[2019, 2020, 2021, 2022, 2023, 2024], n_trials=50)

# Print results
for target, (model, metrics) in results.items():
    print(f"QB {target}:")
    print(f"  CV RMSE: {metrics['cv_rmse_mean']:.2f} +/- {metrics['cv_rmse_std']:.2f}")
    print(f"  Best params: {metrics['best_params']}")

# Verify models saved
print(f"Saved models: {list_models()}")
```

If seasons list causes errors (data not available), try [2021, 2022, 2023, 2024].

Training may take 5-10 minutes with 50 trials. Output should show:
- CV RMSE for passing_yards (expect ~80-120)
- CV RMSE for passing_tds (expect ~0.8-1.2)
  </action>
  <verify>uv run python -c "from lineupiq.models import list_models; models = list_models(); assert ('QB', 'passing_yards') in models; assert ('QB', 'passing_tds') in models; print('QB models saved:', models)"</verify>
  <done>Both QB models (passing_yards, passing_tds) saved to packages/backend/models/</done>
</task>

<task type="auto">
  <name>Task 3: Add QB model tests</name>
  <files>packages/backend/tests/test_qb_models.py</files>
  <action>
Create tests for QB models:
1. test_prepare_qb_data_filters_position - Verify only QB data returned
2. test_prepare_qb_data_returns_correct_features - Feature count matches get_feature_columns()
3. test_train_qb_models_creates_models - Integration test (use n_trials=5 for speed)
4. test_qb_model_predictions_reasonable - Load saved model, predict on sample, verify:
   - passing_yards predictions in range [0, 600]
   - passing_tds predictions in range [0, 8]

Use pytest fixtures to create sample data. For integration tests, use small n_trials to keep fast.
  </action>
  <verify>cd packages/backend && uv run pytest tests/test_qb_models.py -v</verify>
  <done>All QB model tests pass</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] QB training module created with train_qb_models
- [ ] Both QB models trained and saved to packages/backend/models/
- [ ] Model metrics logged (CV RMSE)
- [ ] All QB model tests pass
- [ ] Models produce reasonable predictions (yards 0-600, TDs 0-8)
</verification>

<success_criteria>

- All tasks completed
- QB models for passing_yards and passing_tds trained and persisted
- Cross-validation RMSE documented
- Predictions in reasonable ranges
</success_criteria>

<output>
After completion, create `.planning/phases/05-model-development/05-02-SUMMARY.md`
</output>
