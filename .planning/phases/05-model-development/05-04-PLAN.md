---
phase: 05-model-development
plan: 04
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - packages/backend/src/lineupiq/models/receiver.py
  - packages/backend/tests/test_receiver_models.py
  - packages/backend/models/WR_receiving_yards.joblib
  - packages/backend/models/WR_receiving_tds.joblib
  - packages/backend/models/WR_receptions.joblib
  - packages/backend/models/TE_receiving_yards.joblib
  - packages/backend/models/TE_receiving_tds.joblib
  - packages/backend/models/TE_receptions.joblib
autonomous: true
---

<objective>
Train XGBoost models for WR and TE receiving stats (receiving_yards, receiving_tds, receptions) using Optuna hyperparameter tuning and TimeSeriesSplit validation.

Purpose: Create accurate receiver stat prediction models for WR and TE positions.
Output: Trained and persisted WR and TE models with documented performance metrics.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-model-development/05-RESEARCH.md
@.planning/phases/05-model-development/05-01-SUMMARY.md

@packages/backend/src/lineupiq/features/pipeline.py
@packages/backend/src/lineupiq/models/training.py
@packages/backend/src/lineupiq/models/persistence.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create receiver (WR/TE) model training module</name>
  <files>packages/backend/src/lineupiq/models/receiver.py, packages/backend/src/lineupiq/models/__init__.py</files>
  <action>
Create receiver.py with:
1. `RECEIVER_TARGETS = ["receiving_yards", "receiving_tds", "receptions"]` - Receiving stats
2. `prepare_receiver_data(df, position)`:
   - Filter df where position == position (WR or TE)
   - Drop rows with null values in features or targets
   - Return X (features), y (targets dict)
3. `train_wr_models(seasons, n_trials=50)`:
   - Load features via build_features(seasons)
   - Prepare data via prepare_receiver_data(df, "WR")
   - Train models for each RECEIVER_TARGETS
   - Save with position="WR"
   - Return dict of {target: (model, metrics)}
4. `train_te_models(seasons, n_trials=50)`:
   - Same as train_wr_models but for TE position
   - TEs have different stat distributions (lower volume, fewer TDs)
   - Save with position="TE"

Update __init__.py to export: train_wr_models, train_te_models, RECEIVER_TARGETS

IMPORTANT:
- WR and TE share same targets but different stat distributions
- Train separate models per position for better accuracy
- TE predictions will generally be lower than WR
  </action>
  <verify>uv run python -c "from lineupiq.models import train_wr_models, train_te_models, RECEIVER_TARGETS; print(RECEIVER_TARGETS)"</verify>
  <done>Receiver training module importable with train_wr_models and train_te_models</done>
</task>

<task type="auto">
  <name>Task 2: Train and persist WR models</name>
  <files>packages/backend/models/WR_receiving_yards.joblib, packages/backend/models/WR_receiving_tds.joblib, packages/backend/models/WR_receptions.joblib</files>
  <action>
Run WR model training script:

```python
from lineupiq.models import train_wr_models
from lineupiq.models.persistence import list_models

# Train on recent 6 seasons (match other positions)
results = train_wr_models(seasons=[2019, 2020, 2021, 2022, 2023, 2024], n_trials=50)

# Print results
for target, (model, metrics) in results.items():
    print(f"WR {target}:")
    print(f"  CV RMSE: {metrics['cv_rmse_mean']:.2f} +/- {metrics['cv_rmse_std']:.2f}")
    print(f"  Best params: {metrics['best_params']}")

# Verify models saved
wr_models = [m for m in list_models() if m[0] == "WR"]
print(f"Saved WR models: {wr_models}")
```

Expected RMSE ranges for WR:
- receiving_yards: ~30-50
- receiving_tds: ~0.4-0.7
- receptions: ~2-3
  </action>
  <verify>uv run python -c "from lineupiq.models import list_models; models = [m for m in list_models() if m[0] == 'WR']; assert len(models) == 3; print('WR models saved:', models)"</verify>
  <done>All 3 WR models saved to packages/backend/models/</done>
</task>

<task type="auto">
  <name>Task 3: Train and persist TE models</name>
  <files>packages/backend/models/TE_receiving_yards.joblib, packages/backend/models/TE_receiving_tds.joblib, packages/backend/models/TE_receptions.joblib</files>
  <action>
Run TE model training script:

```python
from lineupiq.models import train_te_models
from lineupiq.models.persistence import list_models

# Train on recent 6 seasons (match other positions)
results = train_te_models(seasons=[2019, 2020, 2021, 2022, 2023, 2024], n_trials=50)

# Print results
for target, (model, metrics) in results.items():
    print(f"TE {target}:")
    print(f"  CV RMSE: {metrics['cv_rmse_mean']:.2f} +/- {metrics['cv_rmse_std']:.2f}")
    print(f"  Best params: {metrics['best_params']}")

# Verify models saved
te_models = [m for m in list_models() if m[0] == "TE"]
print(f"Saved TE models: {te_models}")
```

Expected RMSE ranges for TE (generally lower than WR):
- receiving_yards: ~20-35
- receiving_tds: ~0.3-0.5
- receptions: ~1.5-2.5
  </action>
  <verify>uv run python -c "from lineupiq.models import list_models; models = [m for m in list_models() if m[0] == 'TE']; assert len(models) == 3; print('TE models saved:', models)"</verify>
  <done>All 3 TE models saved to packages/backend/models/</done>
</task>

<task type="auto">
  <name>Task 4: Add WR/TE model tests</name>
  <files>packages/backend/tests/test_receiver_models.py</files>
  <action>
Create tests for receiver models:
1. test_prepare_receiver_data_filters_wr - Verify only WR data returned
2. test_prepare_receiver_data_filters_te - Verify only TE data returned
3. test_train_wr_models_creates_models - Integration test (use n_trials=5)
4. test_train_te_models_creates_models - Integration test (use n_trials=5)
5. test_wr_model_predictions_reasonable - Load saved models, verify:
   - receiving_yards predictions in range [0, 250]
   - receiving_tds predictions in range [0, 4]
   - receptions predictions in range [0, 18]
6. test_te_model_predictions_reasonable - Similar but with TE-appropriate ranges:
   - receiving_yards in range [0, 150]
   - receiving_tds in range [0, 3]
   - receptions in range [0, 12]

Use pytest fixtures for sample data. Keep integration tests fast.
  </action>
  <verify>cd packages/backend && uv run pytest tests/test_receiver_models.py -v</verify>
  <done>All receiver model tests pass</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Receiver training module created with train_wr_models and train_te_models
- [ ] All 3 WR models trained and saved
- [ ] All 3 TE models trained and saved
- [ ] Model metrics logged for all 6 models
- [ ] All receiver model tests pass
- [ ] Predictions in position-appropriate ranges
</verification>

<success_criteria>

- All tasks completed
- WR and TE models for all 3 targets trained and persisted (6 models total)
- Cross-validation RMSE documented for each position/target
- Predictions in reasonable ranges for each position
</success_criteria>

<output>
After completion, create `.planning/phases/05-model-development/05-04-SUMMARY.md`
</output>
